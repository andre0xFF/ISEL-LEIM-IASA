<p align="center">
	<img width="30%" height="30%" src="https://lh5.googleusercontent.com/-vYrwAHpi3Rw/AAAAAAAAAAI/AAAAAAAAAC8/wM0Oxu8ZzDk/photo.jpg">
</p>

# <p align="center">HIGH INSTITUTE OF ENGINEERING OF LISBON</p>

# <p align="center">ARTIFICIAL INTELLIGENCE FOR AUTONOMOUS SYSTEMS</p>


<p align="center">Andr√© Fonseca 39758</p>
<p align="center">afbfonseca@gmail.com</p>
<br/>
<p align="center">March 2017</p>

----------

# Table of contents

[TOC]


# Introduction

This project simulates the interactions between an agent and an environment which the agent belongs to.

When the simulation starts the gatekeeper goes into patrol mode. In case of hearing a noise the gatekeeper inspects the area, searching for the noise's origin. If there is no longer any noise, then he continues to patrol.

At any time the gatekeeper may encounter an enemy and in that case he must protect the area and warn the foe to retreat. In this situation, if the enemy backs off, he will remain inspecting the area for any source of noise. In case the enemy persists, the gatekeeper will have to defend himself and fight the threat.

In combat situation two actions may occur. The gatekeeper can be victorious and defeat the enemy and, then, he goes back to patrol; or in case of defeat the simulation is restarted.

The interaction, at any level, is made by text inputs and outputs.

# 1. Problem analysis

The initial structure of the problem will be decomposed into two roles based on the description of the problem. The first and most obvious role will be the gatekeeper, which will be an autonomous agent and the environment that will provide some type of perceptions to the agent.

## 1.1 Agent nature

The characteristics of the agent can be grouped into a set of design rules - the task environment or PEAS model (Performance, Environment, Actuators, Sensors).

| Agent type | Performance | Environment | Actuators | Sensors |
|:---:|:---:|:---:|:---:|:---:|
| Gatekeeper | Area safety | Computer simulation | Text input | Text output |

## 1.2 Environment nature

The environment where the agent will operate needs to be categorized in order to better design the agent:

* **Fully observable (and known)**: The simulation will occur in a closed and controlled environment and the agent can fully observe the entire environment because the agent's sensors will be able to detect all aspects that are relevant to the choice of actions;

* **Single agent**: As there are not other agents trying to modifying the agent's performance measurement;

* **Deterministic**: The next state of the environment is completely determined by the current state and the action executed by the agent;

* **Static**: The environment does not change while the agent is deliberating;

* **Discrete**: The agent's percepts won't change as time goes by.

## 1.3 Agent program

The base structure of the agent program is to map the agent's percepts to certain actions.

* **Simple reflex agent**: In this problem it is not necessary for the agent to remember his past regarding percepts and actions; because his action depends only on the current percept provided by the environment.

# 2. Models

## 2.1 CRC diagrams

To represent the classes to be used a CRC (Class, Responsibility, Collaborator) card diagram will be designed.

*Unlike in a typical UML class diagram, where a lot of guessing happens when trying to figure out the methods and type of fields, a CRC diagram sketches the responsibility and relationship of each and between elements ending with the simplest possible design resulting in no guess work, less complexity, faster prototyping and dependencies are obvious.*

*When sketching the CRC diagram if one card contains too many responsibilities it might be an hint that something may be wrong. Too many responsibilities violates the [SOLID](https://scotch.io/bar-talk/s-o-l-i-d-the-first-five-principles-of-object-oriented-design) principles.*

<p align="center">
    <img src=http://preview.ibb.co/jSo03v/CRC.png>
</p>

## 2.2 Agent behaviour state machine

The character can transit between states based on the environment events. The transitions are defined by the state machine diagram:

<p align="center">
	<img src="https://image.ibb.co/cmfGtv/RApfy_VTcw_Ypn.png">
</p>


# 3. Implementation

The initial game execution starts evolving the environment and by executing the character, the environment returns the current event and character the current state which both are printed to the console. This sequence of actions runs until the Environment return the exit EnvironmentEvent.

```java
`game.java`

private void execute_game() {

    Scanner scanner = new Scanner(System.in);
    EnvironmentEvent event;

    String event_name = "";
    String behavior_name = "";
    String input = "";

    do {
        this.environment.evolve(input);
        event_name = this.environment.show();

        this.character.execute();
        behavior_name = this.character.show();

        System.out.printf("[ %7s @ %-10s ]$ ", event_name, behavior_name);
        input = scanner.next();

        event = environment.get_event();

    } while(event == null ? true : event != EnvironmentEvent.EXIT);
}
```
The Environment has a collection of EnvironmentEvents that are mapped based on the text input by the user. The environment's evolution simply stored the current event.

```java
`environment.java`

    private Map<String, EnvironmentEvent> events = new HashMap<>();;
    private EnvironmentEvent event;

    public Environment() {
        // Populate environment events
        this.events.put("EXIT", EnvironmentEvent.EXIT);
        this.events.put("NOISE", EnvironmentEvent.NOISE);
        this.events.put("SILENCE", EnvironmentEvent.SILENCE);
        this.events.put("ENEMY", EnvironmentEvent.ENEMY);
        this.events.put("FLEE", EnvironmentEvent.FLEE);
        this.events.put("VICTORY", EnvironmentEvent.VICTORY);
        this.events.put("DEFEAT", EnvironmentEvent.DEFEAT);
    }

    public void evolve(String input) {
        this.event = this.events.get(input.toUpperCase());
    }
```

The character line of execution starts by sensor'ing a percept from the environment, converts the percept into an usable action.

```java
`character.java`

    public void execute() {
        Stimulus stimulus = this.percept();

        if (stimulus != null) {
            Action action = this.process(stimulus);
            this.behave(action);
        }
    }

    private Stimulus percept() {
        return this.environment.get_event();
    }

    private Action process(Stimulus stimulus) {
        return this.behavior.activate(stimulus);
    }

    private void behave(Action action) {
        if(action != null) {
            action.execute();
        }
    }
```

# 4. Results

Example output #1
```
[         @ PATROL     ]$ noise
[   NOISE @ INSPECTION ]$ enemy
[   ENEMY @ DEFEND     ]$ enemy
[   ENEMY @ ATTACK     ]$ victory
[ VICTORY @ PATROL     ]$
```

Example output #2
```
[         @ PATROL     ]$ silence
[ SILENCE @ PATROL     ]$ silence
[ SILENCE @ PATROL     ]$ noise
[   NOISE @ INSPECTION ]$ silence
[ SILENCE @ PATROL     ]$ enemy
[   ENEMY @ DEFEND     ]$ flee
[    FLEE @ INSPECTION ]$ silence
[ SILENCE @ PATROL     ]$
```

# References
1. Artificial Intelligence, A Modern Approach by Stuart Russell and Peter Norvig
